


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,inital-scale=1,user-scalable=no">
  <title> [ Hexo ]</title>
  <!-- bootstrapcss文件 -->
 <!--  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"> -->
<!--   
<link rel="stylesheet" href="/css/zhl.css">

 -->
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/fork-awesome.min.css">
    
      <link rel="stylesheet" href="/css/zhl.css">
    
  
  
<meta name="generator" content="Hexo 6.3.0"></head>
<body>
<div class="container-fluid">
  <div class="row">
  <div id="wrap" class="col-md-12">
    <div id="header">
	<div id="header-left">
	<h1 id="header-title"> 
	<a href="/">
		Hexo
	</a>
	</h1>
	
	</div>
	<div id="header-right">
		
		
		<a href="/"  title="home"><i class="fa fa-home ">home</i></a>
		
		<a target="_blank" rel="noopener" href="https://huchunyu01.github.io"  title="demo"><i class="fa fa-code ">demo</i></a>
		
		<a href="/about"  title="about"><i class="fa fa-user ">about</i></a>
		
		<a href="/"  title="music"><i class="fa fa-music ">music</i></a>
		
		
	</div>
</div>

  </div>
  </div>
  <div id="content" class="row">
    <div id="content-left" class="col-md-4">
      

	

	

	
	<div class="widget-wrap">
		<h3 class="widget-title fa fa-archive">归档</h3>
		<div class="widget">
			<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/">2023</a><span class="archive-list-count">10</span></li></ul>
		</div>
	</div>



    </div>
    <div id="content-right" class="col-md-8">
    
<article id="post">
	<div class="post-title">
  <h1></h1>
  	</div>
  <div class="page-meta">
  	<span class="fa-wrap">
  		<i class="fa fa-clock-o"></i>
  		<span class="date-meta">2023-06-18</span>
  	</span>
  	<span class="fa-wrap">
  		
  	</span>
  	<span class="fa-wrap">
  		
  	</span>
  </div>
  <div class="post-content">
  <hr>
<h2 id="title-Flume"><a href="#title-Flume" class="headerlink" title="title:Flume"></a>title:Flume</h2><p>一、Flume<br>1.安装flume<br>（1）解压<br>把apache-flume-1.9.0-bin.tar.gz进行解压<br>tar zxvf apache-flume-1.9.0-bin.tar.gz</p>
<p><img src="/Flume/01.jpg" alt="img"></p>
<p>（2）添加软链接<br>ln -s apache-flume-1.9.0-bin flume</p>
<p>（3）配置环境变量<br>在&#x2F;etc&#x2F;profile文件中添加以下语句<br>#FLUME_HOME<br>export FLUME_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;flume<br>export PATH&#x3D;$PATH:$FLUME_HOME&#x2F;bin</p>
<p>（4）刷新profile文件<br>source &#x2F;etc&#x2F;profile</p>
<p>（5）查看是否设置成功<br>echo $FLUME_HOME</p>
<p>2.基本使用<br>可以使用flume监听某个端口，人后用netca向这个端口发送数据，flume将接收到的数据打印到控制台上<br>（1）安装netcat<br>yum install -y nc</p>
<p>（2）添加配置文件<br>在netcat-logger.conf中添加以下语句</p>
<h1 id="example1-netcat-logger-conf-单节点Flume配置"><a href="#example1-netcat-logger-conf-单节点Flume配置" class="headerlink" title="example1-netcat-logger.conf: 单节点Flume配置"></a>example1-netcat-logger.conf: 单节点Flume配置</h1><h1 id="定义agent名称为a1"><a href="#定义agent名称为a1" class="headerlink" title="定义agent名称为a1"></a>定义agent名称为a1</h1><h1 id="设置3个组件的名称"><a href="#设置3个组件的名称" class="headerlink" title="设置3个组件的名称"></a>设置3个组件的名称</h1><p>a1.sources &#x3D; r1<br>a1.sinks &#x3D; k1<br>a1.channels &#x3D; c1</p>
<h1 id="配置source类型为NetCat-监听地址为本机，端口为44444"><a href="#配置source类型为NetCat-监听地址为本机，端口为44444" class="headerlink" title="配置source类型为NetCat,监听地址为本机，端口为44444"></a>配置source类型为NetCat,监听地址为本机，端口为44444</h1><p>a1.sources.r1.type &#x3D; netcat<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444<br>#source和channel关联<br>a1.sources.r1.channels &#x3D; c1</p>
<h1 id="配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100"><a href="#配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100" class="headerlink" title="配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100"></a>配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</h1><p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 100</p>
<h1 id="配置sink类型为Logger"><a href="#配置sink类型为Logger" class="headerlink" title="配置sink类型为Logger"></a>配置sink类型为Logger</h1><p>a1.sinks.k1.type &#x3D; logger</p>
<h1 id="将sink绑定到channel上"><a href="#将sink绑定到channel上" class="headerlink" title="将sink绑定到channel上"></a>将sink绑定到channel上</h1><p>a1.sinks.k1.channel &#x3D; c1</p>
<p>（3）启动<br>1）启动agent<br>bin&#x2F;flume-ng agent -n a1 -c conf -f myconf&#x2F;example1-netcat-logger.conf -Dflume.root.logger&#x3D;INFO,console</p>
<p>（4）测试<br>1）使用Netcat测试<br>nc node1 44444</p>
<p>2）观察agent控制台</p>
<p>3.exec_source测试<br>（1）配置文件<br>在example2-exec-source-logger.conf添加以下语句</p>
<h1 id="example2-exec-source-logger-conf"><a href="#example2-exec-source-logger-conf" class="headerlink" title="example2-exec-source-logger.conf"></a>example2-exec-source-logger.conf</h1><p>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1<br>a1.sources.r1.type &#x3D; exec<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.command &#x3D; tail -F &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;shell&#x2F;access.log<br>a1.sources.r1.batchSize &#x3D; 100<br>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 100<br>a1.sinks.k1.type &#x3D; logger<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>（2）启动测试<br>1）准备日志文件</p>
<p>2）准备一个脚本，往日志文件中持续写入数据<br>在脚本中写入以下语句<br>for i in {1..100};<br>do echo ${i} “bigdata log”  &gt;&gt;  access.log ;<br>sleep 0.5;<br>done</p>
<p>3）启动flume采集<br>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example2-exec-source-logger.conf -Dflume.root.logger&#x3D;INFO,console</p>
<p>运行脚本</p>
<ol start="4">
<li>spooldir_source测试<br>（1）配置文件<br>在example3-spooldir-source.conf文件中添加以下语句</li>
</ol>
<p>#example3-spooldir-source.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.type &#x3D; spooldir<br>a1.sources.r1.spoolDir &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;weblog<br>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 100<br>a1.sinks.k1.type &#x3D; logger<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>（2）启动测试<br>bin&#x2F;flume-ng agent -n a1 -c conf -f myconf&#x2F;example3-spooldir-source.conf -Dflume.root.logger&#x3D;INFO,console</p>
<ol start="5">
<li>taildir_source测试<br>（1）配置文件<br>在example4-taildir-source.conf中添加以下语句</li>
</ol>
<p>#example4-taildir-source.conf<br>a1.sources &#x3D; r1<br>a1.sinks &#x3D; k1<br>a1.channels &#x3D; c1<br>a1.sources.r1.type &#x3D; TAILDIR<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.positionFile &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;taildir_position.json<br>a1.sources.r1.filegroups &#x3D; g1 g2<br>a1.sources.r1.filegroups.g1 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;weblog&#x2F;web.*<br>a1.sources.r1.filegroups.g2 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;wxlog&#x2F;wx.*<br>a1.sources.r1.fileHeader &#x3D; true<br>#动态的header-keys eg：filepath&#x3D;&#x2F;..&#x2F;..&#x2F;..&#x2F;<br>a1.sources.r1.fileHeaderKey &#x3D; filepath<br>#写死的header-keys（静态的） eg:a1 &#x3D; aa1<br>a1.sources.r1.headers.g1.a1 &#x3D; aa1<br>a1.sources.r1.headers.g1.b1 &#x3D; bb1<br>a1.sources.r1.headers.g2.a2 &#x3D; aa2<br>a1.sources.r1.headers.g2.b2 &#x3D; bb2<br>a1.sources.r1.maxBatchCount &#x3D; 1000<br>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 10000<br>a1.channels.c1.transactionCapacity &#x3D; 1000<br>a1.sinks.k1.type &#x3D; logger<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>（2）启动测试<br>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f  myconf&#x2F;example4-taildir-source.conf -Dflume.root.logger&#x3D;INFO,console</p>
<p>6.avro source<br>（1）配置文件<br>在example5-avro-source.conf文件中添加以下语句<br>#example5-avro-source.conf<br>a1.sources &#x3D; r1<br>a1.sources.r1.type &#x3D; avro<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 4141</p>
<p>a1.channels &#x3D; c1<br>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 200<br>a1.channels.c1.transactionCapacity &#x3D; 100</p>
<p>a1.sinks &#x3D; k1<br>a1.sinks.k1.type &#x3D; logger<br>a1.sinks.k1.channel &#x3D; c1<br>（2）启动测试<br>1）启动agent<br>bin&#x2F;flume-ng agent -c conf -f  myconf&#x2F;example5-avro-source.conf -n a1 -Dflume.root.logger&#x3D;INFO,console  </p>
<p>2）新建avro-log.txt</p>
<p>7.使用File Channel<br>实现数据持久化<br>（1）配置文件<br>在example6-file-channel.conf中添加以下语句<br>#example6-file-channel.conf</p>
<h1 id="定义agent名称为a1-1"><a href="#定义agent名称为a1-1" class="headerlink" title="定义agent名称为a1"></a>定义agent名称为a1</h1><h1 id="设置3个组件的名称-1"><a href="#设置3个组件的名称-1" class="headerlink" title="设置3个组件的名称"></a>设置3个组件的名称</h1><p>a1.sources &#x3D; r1<br>a1.sinks &#x3D; k1</p>
<h1 id="多个channel使用空格分隔"><a href="#多个channel使用空格分隔" class="headerlink" title="多个channel使用空格分隔"></a>多个channel使用空格分隔</h1><p>a1.channels &#x3D; c1 c2</p>
<h1 id="配置source类型为NetCat-监听地址为本机，端口为44444-1"><a href="#配置source类型为NetCat-监听地址为本机，端口为44444-1" class="headerlink" title="配置source类型为NetCat,监听地址为本机，端口为44444"></a>配置source类型为NetCat,监听地址为本机，端口为44444</h1><p>a1.sources.r1.type &#x3D; netcat<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444</p>
<h1 id="配置sink类型为Logger-1"><a href="#配置sink类型为Logger-1" class="headerlink" title="配置sink类型为Logger"></a>配置sink类型为Logger</h1><p>a1.sinks.k1.type &#x3D; logger</p>
<h1 id="配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100-1"><a href="#配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100-1" class="headerlink" title="配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100"></a>配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</h1><p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 100</p>
<h1 id="配置FileChannel-checkpointDir为检查点文件存储目录，dataDirs为日志数据存储目录，"><a href="#配置FileChannel-checkpointDir为检查点文件存储目录，dataDirs为日志数据存储目录，" class="headerlink" title="配置FileChannel,checkpointDir为检查点文件存储目录，dataDirs为日志数据存储目录，"></a>配置FileChannel,checkpointDir为检查点文件存储目录，dataDirs为日志数据存储目录，</h1><p>a1.channels.c2.type &#x3D; file<br>a1.channels.c2.checkpointDir &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;checkpoint_filechannel<br>a1.channels.c2.dataDirs &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;data_filechannel</p>
<h1 id="将source和sink绑定到channel上"><a href="#将source和sink绑定到channel上" class="headerlink" title="将source和sink绑定到channel上"></a>将source和sink绑定到channel上</h1><h1 id="source同时绑定到c1和c2上"><a href="#source同时绑定到c1和c2上" class="headerlink" title="source同时绑定到c1和c2上"></a>source同时绑定到c1和c2上</h1><p>a1.sources.r1.channels &#x3D; c1 c2<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>（2）可以将-Dflume.root.logger&#x3D;INFO,console添加在conf的环境配置中<br>cp flume-env.sh.template flume-env.sh<br>在flume-env.sh中添加JAVA_OPTS<br>export JAVA_OPTS&#x3D;”-Dflume.root.logger&#x3D;INFO,console”</p>
<p>（3）启动flume<br>bin&#x2F;flume-ng agent -n a1 -c conf -f myconf&#x2F;example6-file-channel.conf -Dflume.root.logger&#x3D;INFO,console</p>
<p>（4）关闭Flume，修改配置文件</p>
<h1 id="将sink绑定到c2上"><a href="#将sink绑定到c2上" class="headerlink" title="将sink绑定到c2上"></a>将sink绑定到c2上</h1><p>a1.sinks.k1.channel &#x3D; c2</p>
<p>（5）重启Flume，可以看到会重新消费c2的数据</p>
<ol start="8">
<li>利用avro source和avro sink实现agent级联<br>（1）配置文件<br>1）在上游node1和node2上配置example7-1-taildir-f-avro.conf<br>vim example7-1-taildir-f-avro.conf</li>
</ol>
<p>#上游服务器配置 example7-1-taildir-f-avro.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1</p>
<p>a1.sources.r1.type &#x3D; TAILDIR<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.positionFile &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;taildir_position.json<br>a1.sources.r1.filegroups &#x3D; g1 g2<br>a1.sources.r1.filegroups.g1 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;weblog&#x2F;web.*<br>a1.sources.r1.filegroups.g2 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;wxlog&#x2F;wx.*<br>#提高吞吐量<br>a1.sources.r1.batchSize &#x3D; 1000<br>#动态的header-keys eg：filepath&#x3D;&#x2F;..&#x2F;..&#x2F;..&#x2F;<br>a1.sources.r1.fileHeaderKey &#x3D; filepath</p>
<p>#拦截器配置，添加header&#x3D;timestamp<br>a1.sources.r1.interceptors &#x3D; i1<br>a1.sources.r1.interceptors.i1.type &#x3D; timestamp<br>a1.sources.r1.interceptors.i1.headerName &#x3D; timestamp</p>
<p>a1.channels.c1.type &#x3D; file<br>#本机数据汇集检查点、event存储目录<br>a1.channels.c1.checkpointDir &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;checkpoint<br>a1.channels.c1.dataDirs &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;data<br>a1.channels.c1.transactionCapacity &#x3D; 2000</p>
<p>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; avro<br>a1.sinks.k1.batch-size &#x3D; 1000<br>#下游目标主机、端口<br>a1.sinks.k1.hostname &#x3D; node3<br>a1.sinks.k1.port &#x3D; 44444</p>
<p>2）在下游服务器node3上配置example7-2-avro-f-hdfs.conf<br>vim example7-2-avro-f-hdfs.conf	<br>#下游服务器配置 example7-2-avro-f-hdfs.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1</p>
<p>#下游数据汇集avro source<br>a1.sources.r1.type &#x3D; avro<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444<br>a1.sources.r1.threads &#x3D; 10<br>a1.sources.r1.batchSize &#x3D; 1000</p>
<p>a1.channels.c1.type &#x3D; file<br>a1.channels.c1.checkpointDir &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;checkpoint<br>a1.channels.c1.dataDirs &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;data<br>a1.channels.c1.transactionCapacity &#x3D; 2000</p>
<p>#hdfs sink<br>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; hdfs<br>a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;node1:8020&#x2F;logdata&#x2F;%Y-%m-%d&#x2F;%H&#x2F;<br>#eg：文件名 logdata_34438hxfd.log，在滚动时，logdata_34438hxfd.log.tmp<br>a1.sinks.k1.hdfs.filePrefix &#x3D; logdata_<br>a1.sinks.k1.hdfs.fileSuffix &#x3D; .log</p>
<p>#三个条件没有优先级，谁先达到就进行滚动<br>#按时间间隔滚动<br>a1.sinks.k1.hdfs.rollInterval &#x3D; 0<br>#按文件大小滚动 256MB<br>a1.sinks.k1.hdfs.rollSize &#x3D; 268435456<br>#按event条数滚动<br>a1.sinks.k1.hdfs.rollCount &#x3D; 100000</p>
<p>a1.sinks.k1.hdfs.batchSize &#x3D; 1000<br>a1.sinks.k1.hdfs.codeC &#x3D; gzip<br>a1.sinks.k1.hdfs.fileType &#x3D; CompressedStream</p>
<p>（2）启动hdfs<br>start-all.sh</p>
<p>（3）启动下游node3上的flume agent<br>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example7-2-avro-f-hdfs.conf -Dflume.root.logger&#x3D;DEBUG,console</p>
<p>（4）在node1和node2上准备两个日志<br>mkdir &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;weblog&#x2F;<br>mkdir &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;wxlog&#x2F;</p>
<p>（5）在node1和node2上利用shell脚本生成日志数据<br>while true<br>do<br>echo webwebwebwebweb &gt;&gt; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;weblog&#x2F;web-access.log<br>echo wxwxwxwxwxwxwx  &gt;&gt; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;wxlog&#x2F;wx-access.log<br>sleep 0.01<br>done</p>
<p>（6）启动node1和node2上的flume agent<br>nohup bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example7-1-taildir-f-avro.conf 1&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</p>
<p>（7）运行脚本，同时查看node3状态和脚本运行结果</p>
<p>9.拦截器<br>（1）Host Interceptor<br>1）配置文件<br>vim example8-interceptor.conf<br>在文件中加入以下语句</p>
<h1 id="example8-interceptor-conf"><a href="#example8-interceptor-conf" class="headerlink" title="example8-interceptor.conf"></a>example8-interceptor.conf</h1><h1 id="定义agent名称为a1-2"><a href="#定义agent名称为a1-2" class="headerlink" title="定义agent名称为a1"></a>定义agent名称为a1</h1><h1 id="设置3个组件的名称-2"><a href="#设置3个组件的名称-2" class="headerlink" title="设置3个组件的名称"></a>设置3个组件的名称</h1><p>a1.sources &#x3D; r1<br>a1.sinks &#x3D; k1<br>a1.channels &#x3D; c1</p>
<h1 id="配置source类型为NetCat-监听地址为本机，端口为44444-2"><a href="#配置source类型为NetCat-监听地址为本机，端口为44444-2" class="headerlink" title="配置source类型为NetCat,监听地址为本机，端口为44444"></a>配置source类型为NetCat,监听地址为本机，端口为44444</h1><p>a1.sources.r1.type &#x3D; netcat<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444</p>
<h1 id="配置拦截器为host"><a href="#配置拦截器为host" class="headerlink" title="配置拦截器为host"></a>配置拦截器为host</h1><p>a1.sources.r1.interceptors &#x3D; i1<br>a1.sources.r1.interceptors.i1.type &#x3D; host</p>
<h1 id="配置sink类型为Logger-2"><a href="#配置sink类型为Logger-2" class="headerlink" title="配置sink类型为Logger"></a>配置sink类型为Logger</h1><p>a1.sinks.k1.type &#x3D; logger</p>
<h1 id="配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100-2"><a href="#配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100-2" class="headerlink" title="配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100"></a>配置channel类型为内存，内存队列最大容量为1000，一个事务中从source接收的Events数量或者发送给sink的Events数量最大为100</h1><p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 100</p>
<h1 id="将source和sink绑定到channel上-1"><a href="#将source和sink绑定到channel上-1" class="headerlink" title="将source和sink绑定到channel上"></a>将source和sink绑定到channel上</h1><p>a1.sources.r1.channels &#x3D; c1<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>2）启动<br>bin&#x2F;flume-ng agent -n a1 -c conf -f myconf&#x2F;example8-interceptor.conf -Dflume.root.logger&#x3D;INFO,console<br>测试输入hello</p>
<p>（2）Timestamp Interceptor<br>1）在文件中加入以下语句<br>a1.sources.r1.interceptors &#x3D; i1 i2<br>a1.sources.r1.interceptors.i1.type &#x3D; host<br>a1.sources.r1.interceptors.i2.type &#x3D; timestamp</p>
<p>2）启动</p>
<p>（3）Static Interceptor<br>1）在文件中加入<br>a1.sources.r1.interceptors &#x3D; i1 i2 i3<br>a1.sources.r1.interceptors.i1.type &#x3D; host<br>a1.sources.r1.interceptors.i2.type &#x3D; timestamp<br>a1.sources.r1.interceptors.i3.type &#x3D; static<br>a1.sources.r1.interceptors.i3.key &#x3D; datacenter<br>a1.sources.r1.interceptors.i3.value &#x3D; NEW_YORK</p>
<p>2）启动测试</p>
<p>（4）UUID Interceptor<br>1）在文件中加入<br>a1.sources.r1.interceptors.i4.type &#x3D; org.apache.flume.sink.solr.morphline.UUIDInterceptor$Builder</p>
<p>2）启动测试</p>
<p>（5）Search and Replace Interceptor<br>1）在文件中加入<br>a1.sources.r1.interceptors.i5.type &#x3D; search_replace<br>a1.sources.r1.interceptors.i5.searchPattern &#x3D; \d{6}<br>a1.sources.r1.interceptors.i5.replaceString &#x3D; ******1234</p>
<p>2）启动测试</p>
<p>（6）自定义拦截器<br>1）把bigdata-flume-interc.jar包，放到flume的lib目录下</p>
<p>2）修改上游服务器配置（node1和node2）<br>在example9-1-taildir-f-avro-interceptor.conf中加入<br>#上游服务器配置example9-1-taildir-f-avro-interceptor.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1</p>
<p>a1.sources.r1.type &#x3D; TAILDIR<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.positionFile &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;taildir_position.json<br>a1.sources.r1.filegroups &#x3D; g1<br>a1.sources.r1.filegroups.g1 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;app&#x2F;event.*<br>#提高吞吐量<br>a1.sources.r1.batchSize &#x3D; 1000<br>#动态的header-keys eg：filepath&#x3D;&#x2F;..&#x2F;..&#x2F;..&#x2F;<br>a1.sources.r1.fileHeaderKey &#x3D; filepath</p>
<p>#拦截器配置,添加自定义拦截器<br>a1.sources.r1.interceptors &#x3D; i1<br>a1.sources.r1.interceptors.i1.type &#x3D; ccjz.rgzn.flume.EventTimestampInterceptor$EventTimestampInterceptorBuilder<br>a1.sources.r1.interceptors.i1.tsFiledName &#x3D; timeStamp<br>a1.sources.r1.interceptors.i1.keyName &#x3D; timestamp<br>a1.sources.r1.interceptors.i1.toEncryFieldName &#x3D; account</p>
<p>a1.channels.c1.type &#x3D; file<br>#本机数据汇集检查点、event存储目录<br>a1.channels.c1.checkpointDir &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;checkpoint<br>a1.channels.c1.dataDirs &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;data<br>a1.channels.c1.transactionCapacity &#x3D; 2000</p>
<p>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; avro<br>a1.sinks.k1.batch-size &#x3D; 1000<br>#下游目标主机、端口<br>a1.sinks.k1.hostname &#x3D; node3<br>a1.sinks.k1.port &#x3D; 44444</p>
<p>3）修改下游配置（node3）<br>在example9-2-avro-f-hdfs-interceptor.conf中加入<br>#下游服务器配置 example9-2-avro-f-hdfs-interceptor.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1</p>
<p>#下游数据汇集avro source<br>a1.sources.r1.type &#x3D; avro<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444<br>a1.sources.r1.threads &#x3D; 10<br>a1.sources.r1.batchSize &#x3D; 1000</p>
<p>a1.channels.c1.type &#x3D; file<br>a1.channels.c1.checkpointDir &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;checkpoint<br>a1.channels.c1.dataDirs &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;data<br>a1.channels.c1.transactionCapacity &#x3D; 2000</p>
<p>#hdfs sink<br>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; hdfs<br>a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;node1:8020&#x2F;logdata-interceptor&#x2F;%Y-%m-%d&#x2F;%H&#x2F;<br>#eg：文件名 logdata_34438hxfd.log，在滚动时，logdata_34438hxfd.log.tmp<br>a1.sinks.k1.hdfs.filePrefix &#x3D; logdata_<br>a1.sinks.k1.hdfs.fileSuffix &#x3D; .log</p>
<p>#三个条件没有优先级，谁先达到就进行滚动<br>#按时间间隔滚动<br>a1.sinks.k1.hdfs.rollInterval &#x3D; 0<br>#按文件大小滚动 256MB<br>a1.sinks.k1.hdfs.rollSize &#x3D; 268435456<br>#按event条数滚动<br>a1.sinks.k1.hdfs.rollCount &#x3D; 100000</p>
<p>a1.sinks.k1.hdfs.batchSize &#x3D; 1000<br>a1.sinks.k1.hdfs.codeC &#x3D; gzip<br>a1.sinks.k1.hdfs.fileType &#x3D; CompressedStream</p>
<p>4）启动hdfs</p>
<p>5）启动下游node3上的flume agent<br>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example9-2-avro-f-hdfs-interceptor.conf -Dflume.root.logger&#x3D;DEBUG,console</p>
<p>6）在node1和node2上传两个日志目录来生成模拟日志数据</p>
<p>7）启动node1和node2上的flume agent<br>nohup bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example9-1-taildir-f-avro-interceptor.conf 1&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</p>
<p>8）去hdfs上查看是否采集到数据</p>
<p>10.Channel选择器<br>（1）Replicating Channel Selector<br>1）配置文件<br>在example10-channel-replicating.conf文件写入<br>#example10-channel-replicating.conf<br>a1.sources &#x3D; r1<br>a1.sinks &#x3D; k1 k2<br>a1.channels &#x3D; c1 c2</p>
<p>a1.sources.r1.type &#x3D; exec<br>a1.sources.r1.channels &#x3D; c1 c2<br>a1.sources.r1.command &#x3D; tail -F &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;logdata&#x2F;access.log<br>a1.sources.r1.batchSize &#x3D; 1000<br>a1.sources.r1.selector.type &#x3D; replicating<br>a1.sources.r1.selector.optional &#x3D; c2</p>
<p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 1000</p>
<p>a1.channels.c2.type &#x3D; memory<br>a1.channels.c2.capacity &#x3D; 1000<br>a1.channels.c2.transactionCapacity &#x3D; 1000</p>
<p>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; hdfs<br>a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;node1:8020&#x2F;logdata_c1&#x2F;%Y-%m-%d&#x2F;%H&#x2F;<br>a1.sinks.k1.hdfs.filePrefix &#x3D; logdata_<br>a1.sinks.k1.hdfs.fileSuffix &#x3D; .log<br>a1.sinks.k1.hdfs.rollInterval &#x3D; 0<br>a1.sinks.k1.hdfs.rollSize &#x3D; 268435456<br>a1.sinks.k1.hdfs.rollCount &#x3D; 0<br>a1.sinks.k1.hdfs.batchSize &#x3D; 1000<br>a1.sinks.k1.hdfs.fileType &#x3D; DataStream<br>a1.sinks.k1.hdfs.useLocalTimeStamp &#x3D; true</p>
<p>a1.sinks.k2.channel &#x3D; c2<br>a1.sinks.k2.type &#x3D; hdfs<br>a1.sinks.k2.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;node1:8020&#x2F;logdata_c2&#x2F;%Y-%m-%d&#x2F;%H&#x2F;<br>a1.sinks.k2.hdfs.filePrefix &#x3D; logdata_<br>a1.sinks.k2.hdfs.fileSuffix &#x3D; .log<br>a1.sinks.k2.hdfs.rollInterval &#x3D; 0<br>a1.sinks.k2.hdfs.rollSize &#x3D; 268435456<br>a1.sinks.k2.hdfs.rollCount &#x3D; 0<br>a1.sinks.k2.hdfs.batchSize &#x3D; 1000<br>a1.sinks.k2.hdfs.fileType &#x3D; DataStream<br>a1.sinks.k2.hdfs.useLocalTimeStamp &#x3D; true</p>
<p>2）启动测试</p>
<p>（2）Multiplexing Channel Selector<br>1）在example11-channel-Multiplexing.conf文件中加入<br>#example11-channel-Multiplexing.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1 c2<br>a1.sinks &#x3D; k1 k2</p>
<p>a1.sources.r1.type &#x3D; TAILDIR<br>a1.sources.r1.channels &#x3D; c1 c2<br>a1.sources.r1.positionFile &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;flumedata&#x2F;taildir_position.json<br>a1.sources.r1.filegroups &#x3D; g1 g2<br>a1.sources.r1.filegroups.g1 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;weblog&#x2F;web.*<br>a1.sources.r1.filegroups.g2 &#x3D; &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;wxlog&#x2F;wx.*<br>a1.sources.r1.headers.g1.logtype &#x3D; web<br>a1.sources.r1.headers.g2.logtype &#x3D; wx</p>
<p>a1.sources.r1.selector.type &#x3D; multiplexing<br>a1.sources.r1.selector.header &#x3D; logtype<br>a1.sources.r1.selector.mapping.web &#x3D; c1<br>a1.sources.r1.selector.mapping.wx &#x3D; c2<br>a1.sources.r1.selector.default &#x3D; c2</p>
<p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 1000</p>
<p>a1.channels.c2.type &#x3D; memory<br>a1.channels.c2.capacity &#x3D; 1000<br>a1.channels.c2.transactionCapacity &#x3D; 1000</p>
<p>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; hdfs<br>a1.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;node1:8020&#x2F;%{logtype}&#x2F;%Y-%m-%d&#x2F;%H&#x2F;<br>a1.sinks.k1.hdfs.filePrefix &#x3D; logdata_<br>a1.sinks.k1.hdfs.fileSuffix &#x3D; .log<br>a1.sinks.k1.hdfs.rollInterval &#x3D; 0<br>a1.sinks.k1.hdfs.rollSize &#x3D; 268435456<br>a1.sinks.k1.hdfs.rollCount &#x3D; 0<br>a1.sinks.k1.hdfs.batchSize &#x3D; 1000<br>a1.sinks.k1.hdfs.fileType &#x3D; DataStream<br>a1.sinks.k1.hdfs.useLocalTimeStamp &#x3D; true</p>
<p>a1.sinks.k2.channel &#x3D; c2<br>a1.sinks.k2.type &#x3D; hdfs<br>a1.sinks.k2.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;node1:8020&#x2F;%{logtype}&#x2F;%Y-%m-%d&#x2F;%H&#x2F;<br>a1.sinks.k2.hdfs.filePrefix &#x3D; logdata_<br>a1.sinks.k2.hdfs.fileSuffix &#x3D; .log<br>a1.sinks.k2.hdfs.rollInterval &#x3D; 0<br>a1.sinks.k2.hdfs.rollSize &#x3D; 268435456<br>a1.sinks.k2.hdfs.rollCount &#x3D; 0<br>a1.sinks.k2.hdfs.batchSize &#x3D; 1000<br>a1.sinks.k2.hdfs.fileType &#x3D; DataStream<br>a1.sinks.k2.hdfs.useLocalTimeStamp &#x3D; true</p>
<p>2）启动测试</p>
<ol start="11">
<li>Sink处理器<br>（1）Failover Sink Processor<br>1）在上游配置文件（node1）<br>在example12-1-sink-failover.conf中输入</li>
</ol>
<p>#example12-1-sink-failover.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1 k2</p>
<p>a1.sources.r1.type &#x3D; exec<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.command &#x3D; tail -F &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;logdata&#x2F;access.log<br>a1.sources.r1.batchSize &#x3D; 1000</p>
<p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 1000</p>
<p>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; avro<br>a1.sinks.k1.hostname &#x3D; node2<br>a1.sinks.k1.port &#x3D; 44444<br>a1.sinks.k1.batch-size &#x3D; 1000</p>
<p>a1.sinks.k2.channel &#x3D; c1<br>a1.sinks.k2.type &#x3D; avro<br>a1.sinks.k2.hostname &#x3D; node3<br>a1.sinks.k2.port &#x3D; 44444<br>a1.sinks.k2.batch-size &#x3D; 1000</p>
<p>a1.sinkgroups &#x3D; g1<br>a1.sinkgroups.g1.sinks &#x3D; k1 k2<br>a1.sinkgroups.g1.processor.type &#x3D; failover<br>a1.sinkgroups.g1.processor.priority.k1 &#x3D; 200<br>a1.sinkgroups.g1.processor.priority.k2 &#x3D; 100<br>a1.sinkgroups.g1.processor.maxpenalty &#x3D; 5000</p>
<p>2）在下游配置文件（node2和node3）<br>在example12-2-sink-failover.conf文件中输入<br>#example12-2-sink-failover.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1</p>
<p>a1.sources.r1.type &#x3D; avro<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444<br>a1.sources.r1.threads &#x3D; 10<br>a1.sources.r1.batchSize &#x3D; 1000</p>
<p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 1000</p>
<p>a1.sinks.k1.type &#x3D; logger<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>3）保证hdfs正常启动</p>
<p>4）启动下游node2和node3<br>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example12-2-sink-failover.conf -Dflume.root.logger&#x3D;DEBUG,console</p>
<p>5）上游node1启动</p>
<p>（2）Load balancing Sink Processor<br> 1）在上游进行flume配置（node1）<br>在example13-1-sink-loadbalance.conf中加入<br>#example13-1-sink-loadbalance.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1 k2</p>
<p>a1.sources.r1.type &#x3D; exec<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.command &#x3D; tail -F &#x2F;export&#x2F;data&#x2F;flume-example-data&#x2F;logdata&#x2F;access.log<br>a1.sources.r1.batchSize &#x3D; 1000</p>
<p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 1000</p>
<p>a1.sinks.k1.channel &#x3D; c1<br>a1.sinks.k1.type &#x3D; avro<br>a1.sinks.k1.hostname &#x3D; node2<br>a1.sinks.k1.port &#x3D; 44444<br>a1.sinks.k1.batch-size &#x3D; 1000</p>
<p>a1.sinks.k2.channel &#x3D; c1<br>a1.sinks.k2.type &#x3D; avro<br>a1.sinks.k2.hostname &#x3D; node3<br>a1.sinks.k2.port &#x3D; 44444<br>a1.sinks.k2.batch-size &#x3D; 1000</p>
<p>a1.sinkgroups &#x3D; g1<br>a1.sinkgroups.g1.sinks &#x3D; k1 k2<br>a1.sinkgroups.g1.processor.type &#x3D; load_balance<br>a1.sinkgroups.g1.processor.backoff &#x3D; true<br>a1.sinkgroups.g1.processor.selector &#x3D; round_robin</p>
<p>2）在下游flume配置（node2和node3）<br>在example13-2-sink-loadbalance.conf中加入<br>#example13-2-sink-loadbalance.conf<br>a1.sources &#x3D; r1<br>a1.channels &#x3D; c1<br>a1.sinks &#x3D; k1</p>
<p>a1.sources.r1.type &#x3D; avro<br>a1.sources.r1.channels &#x3D; c1<br>a1.sources.r1.bind &#x3D; 0.0.0.0<br>a1.sources.r1.port &#x3D; 44444<br>a1.sources.r1.threads &#x3D; 10<br>a1.sources.r1.batchSize &#x3D; 1000</p>
<p>a1.channels.c1.type &#x3D; memory<br>a1.channels.c1.capacity &#x3D; 1000<br>a1.channels.c1.transactionCapacity &#x3D; 1000</p>
<p>a1.sinks.k1.type &#x3D; logger<br>a1.sinks.k1.channel &#x3D; c1</p>
<p>3）启动下游（node2和node3）<br>bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example13-2-sink-loadbalance.conf -Dflume.root.logger&#x3D;DEBUG,console</p>
<p>4）启动上游（node1）<br>nohup bin&#x2F;flume-ng agent -n a1 -c conf&#x2F; -f myconf&#x2F;example13-1-sink-loadbalance.conf 1&gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</p>

	</div>
</article>



    </div>
  </div>
  <div class="row">
<div id="bottom" class="col-md-12"> 
  <div class="bottom-nav">
	
	
	<a href="https://github.com/lizehongss" class="fa fa-github fa-2x" target="_blank" title="Follow me" ></a>
	
	
</div>
<div class="bottom-info">
	&copy; 2023 John Doe<br>
	Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	theme <a href="https://github.com/lizehongss/hexo-theme-zhl" target="_blank">zhl</a>
</div>
</div>
</div>
</div>
<div id="tool">
  <ul>
    <li class="fa fa-angle-up top" id="top"></li>
  </ul>
</div>
  <div class="bg_content">
    <canvas id="canvas"></canvas>
  </div>
  
  <!-- scripts list from theme config.yml -->
  
    <script src="/js/zhl.js"></script>
  
    <script src="/js/bj.js"></script>
  

<!-- jQ cdn  -->
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
<!-- bootstrap js cdn-->
<!-- <script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script> -->


</body>
</html>
